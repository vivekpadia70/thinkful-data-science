{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.cluster import KMeans, MeanShift, SpectralClustering\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "import nltk\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "poems = gutenberg.raw('blake-poems.txt')\n",
    "stories = gutenberg.raw('bryant-stories.txt')\n",
    "busterbrown = gutenberg.raw('burgess-busterbrown.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "ball = gutenberg.raw('chesterton-ball.txt')\n",
    "parents = gutenberg.raw('edgeworth-parents.txt')\n",
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
    "paradise = gutenberg.raw('milton-paradise.txt')\n",
    "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "poems = re.sub(r'CHAPTER .*', '', poems)\n",
    "stories = re.sub(r'CHAPTER .*', '', stories)\n",
    "busterbrown = re.sub(r'CHAPTER .*', '', busterbrown)\n",
    "ball = re.sub(r'CHAPTER .*', '', ball)\n",
    "parents = re.sub(r'CHAPTER .*', '', parents)\n",
    "moby_dick = re.sub(r'CHAPTER .*', '', moby_dick)\n",
    "paradise = re.sub(r'CHAPTER .*', '', paradise)\n",
    "hamlet = re.sub(r'CHAPTER .*', '', hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease size of our text dataset\n",
    "\n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])\n",
    "poems = text_cleaner(poems[:int(len(poems)/10)])\n",
    "stories = text_cleaner(stories[:int(len(stories)/10)])\n",
    "busterbrown = text_cleaner(busterbrown[:int(len(busterbrown)/10)])\n",
    "ball = text_cleaner(ball[:int(len(ball)/10)])\n",
    "parents = text_cleaner(parents[:int(len(parents)/10)])\n",
    "moby_dick = text_cleaner(moby_dick[:int(len(moby_dick)/10)])\n",
    "paradise = text_cleaner(paradise[:int(len(paradise)/10)])\n",
    "hamlet = text_cleaner(hamlet[:int(len(hamlet)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\",\n",
       " 'So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.',\n",
       " \"There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\",\n",
       " 'Oh dear!',\n",
       " \"I shall be late!'\",\n",
       " '(when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.',\n",
       " 'In another moment down went Alice after it, never once considering how in the world she was to get out again.',\n",
       " 'The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.',\n",
       " 'Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next.',\n",
       " 'First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs.',\n",
       " \"She took down a jar from one of the shelves as she passed; it was labelled 'ORANGE MARMALADE', but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.\",\n",
       " \"'Well!'\",\n",
       " \"thought Alice to herself, 'after such a fall as this, I shall think nothing of tumbling down stairs!\",\n",
       " \"How brave they'll all think me at home!\",\n",
       " \"Why, I wouldn't say anything about it, even if I fell off the top of the house!'\",\n",
       " '(Which was very likely true.)',\n",
       " 'Down, down, down.',\n",
       " 'Would the fall NEVER come to an end!',\n",
       " \"'I wonder how many miles I've fallen by this time?'\",\n",
       " 'she said aloud.',\n",
       " \"'I must be getting somewhere near the centre of the earth.\",\n",
       " \"Let me see: that would be four thousand miles down, I think ' (for, you see, Alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a VERY good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) ' yes, that's about the right distance but then I wonder what Latitude or Longitude I've got to?'\",\n",
       " '(Alice had no idea what Latitude was, or Longitude either, but thought they were nice grand words to say.)',\n",
       " 'Presently she began again.',\n",
       " \"'I wonder if I shall fall right THROUGH the earth!\",\n",
       " \"How funny it'll seem to come out among the people that walk with their heads downward!\",\n",
       " \"The Antipathies, I think ' (she was rather glad there WAS no one listening, this time, as it didn't sound at all the right word) ' but I shall have to ask them what the name of the country is, you know.\",\n",
       " \"Please, Ma'am, is this New Zealand or Australia?'\",\n",
       " \"(and she tried to curtsey as she spoke fancy CURTSEYING as you're falling through the air!\",\n",
       " 'Do you think you could manage it?)',\n",
       " \"'And what an ignorant little girl she'll think me for asking!\",\n",
       " \"No, it'll never do to ask: perhaps I shall see it written up somewhere.'\",\n",
       " 'Down, down, down.',\n",
       " 'There was nothing else to do, so Alice soon began talking again.',\n",
       " \"'Dinah'll miss me very much to-night, I should think!'\",\n",
       " '(Dinah was the cat.)',\n",
       " \"'I hope they'll remember her saucer of milk at tea-time.\",\n",
       " 'Dinah my dear!',\n",
       " 'I wish you were down here with me!',\n",
       " \"There are no mice in the air, I'm afraid, but you might catch a bat, and that's very like a mouse, you know.\",\n",
       " \"But do cats eat bats, I wonder?'\",\n",
       " \"And here Alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, 'Do cats eat bats?\",\n",
       " \"Do cats eat bats?'\",\n",
       " \"and sometimes, 'Do bats eat cats?'\",\n",
       " \"for, you see, as she couldn't answer either question, it didn't much matter which way she put it.\",\n",
       " \"She felt that she was dozing off, and had just begun to dream that she was walking hand in hand with Dinah, and saying to her very earnestly, 'Now, Dinah, tell me the truth: did you ever eat a bat?'\",\n",
       " 'when suddenly, thump!',\n",
       " 'thump!',\n",
       " 'down she came upon a heap of sticks and dry leaves, and the fall was over.',\n",
       " 'Alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the White Rabbit was still in sight, hurrying down it.',\n",
       " \"There was not a moment to be lost: away went Alice like the wind, and was just in time to hear it say, as it turned a corner, 'Oh my ears and whiskers, how late it's getting!'\",\n",
       " 'She was close behind it when she turned the corner, but the Rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof.',\n",
       " 'There were doors all round the hall, but they were all locked; and when Alice had been all the way down one side and up the other, trying every door, she walked sadly down the middle, wondering how she was ever to get out again.',\n",
       " \"Suddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and Alice's first thought was that it might belong to one of the doors of the hall; but, alas!\",\n",
       " 'either the locks were too large, or the key was too small, but at any rate it would not open any of them.',\n",
       " 'However, on the second time round, she came upon a low curtain she had not noticed before, and behind it was a little door about fifteen inches high: she tried the little golden key in the lock, and to her great delight it fitted!',\n",
       " 'Alice opened the door and found that it led into a small passage, not much larger than a rat-hole: she knelt down and looked along the passage into the loveliest garden you ever saw.',\n",
       " \"How she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head through the doorway; 'and even if my head would go through,' thought poor Alice, 'it would be of very little use without my shoulders.\",\n",
       " 'Oh, how I wish I could shut up like a telescope!',\n",
       " \"I think I could, if I only know how to begin.'\",\n",
       " 'For, you see, so many out-of-the-way things had happened lately, that Alice had begun to think that very few things indeed were really impossible.',\n",
       " \"There seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, ('which certainly was not here before,' said Alice,) and round the neck of the bottle was a paper label, with the words 'DRINK ME' beautifully printed on it in large letters.\",\n",
       " \"It was all very well to say 'Drink me,' but the wise little Alice was not going to do THAT in a hurry.\",\n",
       " '\\'No, I\\'ll look first,\\' she said, \\'and see whether it\\'s marked \"poison\" or not\\'; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they WOULD not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger VERY deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked \\'poison,\\' it is almost certain to disagree with you, sooner or later.',\n",
       " \"However, this bottle was NOT marked 'poison,' so Alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,) she very soon finished it off.\",\n",
       " \"* * * * * * * * * * * * * * * * * * * * 'What a curious feeling!'\",\n",
       " \"said Alice; 'I must be shutting up like a telescope.'\",\n",
       " 'And so it was indeed: she was now only ten inches high, and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden.',\n",
       " \"First, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; 'for it might end, you know,' said Alice to herself, 'in my going out altogether, like a candle.\",\n",
       " \"I wonder what I should be like then?'\",\n",
       " 'And she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.',\n",
       " 'After a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor Alice!',\n",
       " 'when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried.',\n",
       " \"'Come, there's no use in crying like that!'\",\n",
       " \"said Alice to herself, rather sharply; 'I advise you to leave off this minute!'\",\n",
       " 'She generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people.',\n",
       " \"'But it's no use now,' thought poor Alice, 'to pretend to be two people!\",\n",
       " \"Why, there's hardly enough of me left to make ONE respectable person!'\",\n",
       " \"Soon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words 'EAT ME' were beautifully marked in currants.\",\n",
       " \"'Well, I'll eat it,' said Alice, 'and if it makes me grow larger, I can reach the key; and if it makes me grow smaller, I can creep under the door; so either way I'll get into the garden, and I don't care which happens!'\",\n",
       " \"She ate a little bit, and said anxiously to herself, 'Which way?\",\n",
       " 'Which way?',\n",
       " \"', holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size: to be sure, this generally happens when one eats cake, but Alice had got so much into the way of expecting nothing but out-of-the-way things to happen, that it seemed quite dull and stupid for life to go on in the common way.\",\n",
       " 'So she set to work, and very soon finished off the cake.',\n",
       " \"* * * * * * * * * * * * * * * * * * * * 'Curiouser and curiouser!'\",\n",
       " \"cried Alice (she was so much surprised, that for the moment she quite forgot how to speak good English); 'now I'm opening out like the largest telescope that ever was!\",\n",
       " \"Good-bye, feet!'\",\n",
       " '(for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off).',\n",
       " \"'Oh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears?\",\n",
       " \"I'm sure _I_ shan't be able!\",\n",
       " \"I shall be a great deal too far off to trouble myself about you: you must manage the best way you can; but I must be kind to them,' thought Alice, 'or perhaps they won't walk the way I want to go!\",\n",
       " \"Let me see: I'll give them a new pair of boots every Christmas.'\",\n",
       " 'And she went on planning to herself how she would manage it.',\n",
       " \"'They must go by the carrier,' she thought; 'and how funny it'll seem, sending presents to one's own feet!\",\n",
       " 'And how odd the directions will look!',\n",
       " \"ALICE'S RIGHT FOOT, ESQ.\",\n",
       " \"HEARTHRUG, NEAR THE FENDER, (WITH ALICE'S LOVE).\",\n",
       " \"Oh dear, what nonsense I'm talking!'\",\n",
       " 'Just then her head struck against the roof of the hall: in fact she was now more than nine feet high, and she at once took up the little golden key and hurried off to the garden door.',\n",
       " 'Poor Alice!',\n",
       " 'It was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again.',\n",
       " \"'You ought to be ashamed of yourself,' said Alice, 'a great girl like you,' (she might well say this), 'to go on crying in this way!\",\n",
       " \"Stop this moment, I tell you!'\",\n",
       " 'But she went on all the same, shedding gallons of tears, until there was a large pool all round her, about four inches deep and reaching half down the hall.',\n",
       " 'After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming.',\n",
       " \"It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came, 'Oh!\",\n",
       " 'the Duchess, the Duchess!',\n",
       " 'Oh!',\n",
       " \"won't she be savage if I've kept her waiting!'\",\n",
       " \"Alice felt so desperate that she was ready to ask help of any one; so, when the Rabbit came near her, she began, in a low, timid voice, 'If you please, sir ' The Rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go.\",\n",
       " \"Alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking: 'Dear, dear!\",\n",
       " 'How queer everything is to-day!',\n",
       " 'And yesterday things went on just as usual.',\n",
       " \"I wonder if I've been changed in the night?\",\n",
       " 'Let me think: was I the same when I got up this morning?',\n",
       " 'I almost think I can remember feeling a little different.',\n",
       " \"But if I'm not the same, the next question is, Who in the world am I?\",\n",
       " 'Ah']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the paragraph into text and it's labels\n",
    "\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in nltk.sent_tokenize(alice)]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in nltk.sent_tokenize(persuasion)]\n",
    "poems_sents = [[sent, \"Blake\"] for sent in nltk.sent_tokenize(poems)]\n",
    "stories_sents = [[sent, \"Bryant\"] for sent in nltk.sent_tokenize(stories)]\n",
    "busterbrown_sents = [[sent, \"Burgess\"] for sent in nltk.sent_tokenize(busterbrown)]\n",
    "ball_sents = [[sent, \"Chesterton\"] for sent in nltk.sent_tokenize(ball)]\n",
    "parents_sents = [[sent, \"Edgeworth\"] for sent in nltk.sent_tokenize(parents)]\n",
    "moby_dick_sents = [[sent, \"Melville\"] for sent in nltk.sent_tokenize(moby_dick)]\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in nltk.sent_tokenize(paradise)]\n",
    "hamlet_sents = [[sent, \"Shakespeare\"] for sent in nltk.sent_tokenize(hamlet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh dear!</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I shall be late!'</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  Alice was beginning to get very tired of sitti...  Carroll\n",
       "1  So she was considering in her own mind (as wel...  Carroll\n",
       "2  There was nothing so VERY remarkable in that; ...  Carroll\n",
       "3                                           Oh dear!  Carroll\n",
       "4                                  I shall be late!'  Carroll"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.DataFrame(alice_sents + persuasion_sents + poems_sents + stories_sents + busterbrown_sents + ball_sents + parents_sents + moby_dick_sents + paradise_sents + hamlet_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition\n",
    "\n",
    "For decreasing the features size of our data we need to use some technique of decomposition. We can't simply use PCA for text vectors so we'll be comparing two other techniques which are used for reducing text features.\n",
    "    \n",
    "    1. TruncatedSVD or LSA (Latent Semantic Analysis)\n",
    "    2. LDA (Latend Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sentences[0]\n",
    "Y = sentences[1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a tfidf vector for converting text data into numerical form\n",
    "cluster_vectorizer = TfidfVectorizer()\n",
    "X_cluster = cluster_vectorizer.fit_transform(X_train).toarray()\n",
    "Y_cluster = Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation()\n",
    "x_lda = lda.fit_transform(X_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200726160869298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>31</td>\n",
       "      <td>141</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>19</td>\n",
       "      <td>332</td>\n",
       "      <td>151</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>64</td>\n",
       "      <td>284</td>\n",
       "      <td>111</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         0    1    2   3   4   5   6   7   8   9\n",
       "1                                                    \n",
       "Austen        3  141   11   5   6   5   9   4   9   5\n",
       "Blake         1   11    1   1   1   0   0   1   1   1\n",
       "Bryant       26  110   45  14   7  15   6  23  10   2\n",
       "Burgess       2   57   11   1   1   0   0   2   4   2\n",
       "Carroll       1   64    8   0   4   1   6   1   2   3\n",
       "Chesterton   31  141   45  30  12  20  18  11  17  13\n",
       "Edgeworth    19  332  151  12  13  10   7   7  15  18\n",
       "Melville     64  284  111  60  55  55  32  51  49  43\n",
       "Milton       14   33   31  18   8  13  10  12   9  15\n",
       "Shakespeare  15   28   40   5   6  12  17  20   6   9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_lda = KMeans(n_clusters=10)\n",
    "kmeans_lda.fit(x_lda)\n",
    "y_predict = kmeans_lda.predict(x_lda)\n",
    "print(silhouette_score(x_lda, kmeans_lda.labels_))\n",
    "pd.crosstab(Y_cluster, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our silhouette score is not so bad for LDA. Now let's check this data on Mean Shift algorithm to check what number of clusters it chooses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>187</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>208</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>292</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>427</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>684</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>130</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>109</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          0    1\n",
       "1                    \n",
       "Austen       187   11\n",
       "Blake         17    1\n",
       "Bryant       208   50\n",
       "Burgess       69   11\n",
       "Carroll       79   11\n",
       "Chesterton   292   46\n",
       "Edgeworth    427  157\n",
       "Melville     684  120\n",
       "Milton       130   33\n",
       "Shakespeare  109   49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanshift_lda = MeanShift()\n",
    "meanshift_lda.fit(x_lda)\n",
    "y_pred = meanshift_lda.predict(x_lda)\n",
    "pd.crosstab(Y_cluster, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Shift does not require to specify the number of clusters as it uses automatically chooses appropriate number of clusters and tries to fit our model based on that number. We only use this method when our data is small because it takes a lot of time to train.\n",
    "\n",
    "For LDA MeanShift worked well but looking at crosstab we see that it only has 2 clusters. So, it makes it less reliable than k-means with 10 clusters as we know the number of authors in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=40)\n",
    "x_svd = svd.fit_transform(X_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013103230087110425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>46</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>93</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>60</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>107</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>201</td>\n",
       "      <td>108</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>256</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>35</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          0    1   2   3   4   5    6    7   8   9\n",
       "1                                                      \n",
       "Austen        30   52   9   4   2  25   23   37   4  12\n",
       "Blake          2    3   2   0   3   0    2    6   0   0\n",
       "Bryant        46   17  13   2   4  28   37   53  35  23\n",
       "Burgess        7    7   4   4   1   0   30   22   1   4\n",
       "Carroll        5    8   3   3   2  32    1   28   4   4\n",
       "Chesterton    93   32  50  12   9   0   62   45  19  16\n",
       "Edgeworth     60   73  18  26  13  64  107   92  86  45\n",
       "Melville     201  108  65  11  40   5   65  256  26  27\n",
       "Milton        35   75   5   5   1   0    5   26   0  11\n",
       "Shakespeare    5   23  10   6  20   2    3   77  11   1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_svd = KMeans(n_clusters=10)\n",
    "kmeans_svd.fit(x_svd)\n",
    "y_predict = kmeans_svd.predict(x_svd)\n",
    "print(silhouette_score(x_svd, kmeans_svd.labels_))\n",
    "pd.crosstab(Y_cluster, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e983df71e637>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmeanshift_svd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeanShift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmeanshift_svd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_svd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_svd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeanshift_svd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeanshift_svd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_svd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_cluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\mean_shift_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    423\u001b[0m                        \u001b[0mmin_bin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_bin_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m                        \u001b[0mbin_seeding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbin_seeding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                        cluster_all=self.cluster_all, n_jobs=self.n_jobs)\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\mean_shift_.py\u001b[0m in \u001b[0;36mmean_shift\u001b[1;34m(X, bandwidth, seeds, bin_seeding, min_bin_freq, cluster_all, max_iter, n_jobs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     all_res = Parallel(n_jobs=n_jobs)(\n\u001b[0;32m    204\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_mean_shift_single_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         (seed, X, nbrs, max_iter) for seed in seeds)\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;31m# copy results in a dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\mean_shift_.py\u001b[0m in \u001b[0;36m_mean_shift_single_seed\u001b[1;34m(my_mean, X, nbrs, max_iter)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# Find mean of points within bandwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         i_nbrs = nbrs.radius_neighbors([my_mean], bandwidth,\n\u001b[1;32m---> 97\u001b[1;33m                                        return_distance=False)[0]\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mpoints_within\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_nbrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints_within\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[1;34m(self, X, radius, return_distance)\u001b[0m\n\u001b[0;32m    745\u001b[0m             results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0;32m    746\u001b[0m                 \u001b[0mdelayed_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m             )\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_radius_parallel_helper\u001b[1;34m(tree, data, radius, return_distance)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[0mcloudpickle\u001b[0m \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \"\"\"\n\u001b[1;32m--> 580\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_radius\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meanshift_svd = MeanShift()\n",
    "meanshift_svd.fit(x_svd)\n",
    "print(silhouette_score(x_svd, meanshift_svd.labels_))\n",
    "y_pred = meanshift_svd.predict(x_svd)\n",
    "pd.crosstab(Y_cluster, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both these models performed very poorly for TruncatedSVD and as per other machine learning experts LDA tends to be much more reliable compared to LSA which is clearly observed in our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12021922695261111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>468</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>402</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         0   1   2    3   4   5   6   7   8   9\n",
       "1                                                   \n",
       "Austen        6   7   2  157   7   5   5   7   8   5\n",
       "Blake         0   2   0   13   1   0   3   2   1   0\n",
       "Bryant        5   3   4  172   4  13  13  13  10   8\n",
       "Burgess       1   3   2   61   0   3   1   2   7   2\n",
       "Carroll       3   3   1   70   0   0   2   5   2   2\n",
       "Chesterton   22  17   3  198  18  12  17  25  18  10\n",
       "Edgeworth     4   5   5  468  14  19  12  12   9   9\n",
       "Melville     52  48  44  402  43  34  47  52  44  63\n",
       "Milton       15  10   9   53   6  10  19  12  10   8\n",
       "Shakespeare  11  24  10   43   6  15   9  26  15   8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclustering = SpectralClustering(n_clusters=10, random_state=40)\n",
    "y_pred = sclustering.fit_predict(x_lda)\n",
    "print(silhouette_score(x_svd, sclustering.labels_))\n",
    "pd.crosstab(Y_cluster, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpectralClustering is doing very poor job so we won't be looking into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melville       1090\n",
       "Edgeworth       778\n",
       "Chesterton      439\n",
       "Bryant          327\n",
       "Austen          280\n",
       "Shakespeare     210\n",
       "Milton          210\n",
       "Carroll         118\n",
       "Burgess         108\n",
       "Blake            28\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing methods\n",
    "\n",
    "We will try TfidfVectorizer and CountVectorizer for converting our data into numerical form. Next we would compare both those models for higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, Y_train)\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(X_train)\n",
    "X_train_count, X_test_count, y_train, y_test = train_test_split(X_count, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Modeling\n",
    "\n",
    "Now let's make some models with labels available to us. We'll try 3 different supervised models, RandomForestClassifier, GradientBoostingClassifier and LogisticRegression and see which works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Train score:  0.30360460795243405\n",
      "Tfidf Test score:  0.3032329988851728\n",
      "Count Train score:  0.3240431066518023\n",
      "Count Test score:  0.30992196209587514\n"
     ]
    }
   ],
   "source": [
    "# random forest with tfidf vectorizer\n",
    "rfc_tfidf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=30)\n",
    "rfc_tfidf.fit(X_tfidf, Y)\n",
    "print(\"Tfidf Train score: \", rfc_tfidf.score(X_train_tfidf, Y_train))\n",
    "\n",
    "# random forest with count vectorizer\n",
    "rfc_count = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=30)\n",
    "rfc_count.fit(X_count, Y)\n",
    "print(\"Count Train score: \", rfc_count.score(X_train_count, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Train score:  0.1958379784466741\n",
      "Tfidf Test score:  0.20624303232998886\n",
      "Count Train score:  0.8454106280193237\n",
      "Count Test score:  0.8472686733556298\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting with tfidf vectorizer\n",
    "gbc_tfidf = GradientBoostingClassifier()\n",
    "gbc_tfidf.fit(X_tfidf, Y)\n",
    "print(\"Tfidf Train score: \", gbc_tfidf.score(X_train_tfidf, Y_train))\n",
    "\n",
    "# Gradient boosting with count vectorizer\n",
    "gbc_count = GradientBoostingClassifier()\n",
    "gbc_count.fit(X_count, Y)\n",
    "print(\"Count Train score: \", gbc_count.score(X_train_count, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Train score:  0.8199554069119287\n",
      "Tfidf Test score:  0.2129319955406912\n",
      "Count Train score:  0.9535488665923448\n",
      "Count Test score:  0.9509476031215162\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with tfidf Vectorizer\n",
    "lr_tfidf = LogisticRegression()\n",
    "lr_tfidf.fit(X_tfidf, Y)\n",
    "print(\"Tfidf Train score: \", lr_tfidf.score(X_tfidf, Y))\n",
    "\n",
    "# Logistic Regression with count vectorizer\n",
    "lr_count = LogisticRegression()\n",
    "lr_count.fit(X_count, Y)\n",
    "print(\"Count Train score: \", lr_count.score(X_train_count, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model from supervised learning is Logistic Regression with accuracy of 95% in both train and test dataset. Best performing vectorizer is CountVectorizer in every model. TfidfVectorizer tends to overfitting in LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervise modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation()\n",
    "x_lda = lda.fit_transform(X_train_count)\n",
    "x_test_count = lda.transform(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05      , 0.05      , 0.05000001, ..., 0.05000001, 0.05000001,\n",
       "        0.05000001],\n",
       "       [0.00322683, 0.00322628, 0.00322641, ..., 0.00322651, 0.00322581,\n",
       "        0.00322648],\n",
       "       [0.00344935, 0.00344868, 0.00344876, ..., 0.00344832, 0.00344828,\n",
       "        0.00344847],\n",
       "       ...,\n",
       "       [0.8499943 , 0.01666818, 0.01666683, ..., 0.01666667, 0.01666693,\n",
       "        0.01666706],\n",
       "       [0.01111453, 0.01111244, 0.01111167, ..., 0.01111196, 0.01111111,\n",
       "        0.01111224],\n",
       "       [0.45265053, 0.00400032, 0.11696069, ..., 0.00400014, 0.004     ,\n",
       "        0.00400016]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count = pad_sequences(x_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 10, 128)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 908,553\n",
      "Trainable params: 908,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(4000, 128,input_length = X_train_count.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(256, dropout_U=0.2, dropout_W=0.2, return_sequences=False))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edgeworth      428\n",
       "Chesterton     250\n",
       "Bryant         182\n",
       "Austen         158\n",
       "Milton         121\n",
       "Shakespeare    111\n",
       "Carroll         75\n",
       "Burgess         65\n",
       "Blake           14\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Austen  Blake  Bryant  Burgess  Carroll  Chesterton  Edgeworth  Milton  \\\n",
      "2417       0      0       0        0        0           0          0       0   \n",
      "1791       0      0       0        0        0           0          1       0   \n",
      "1666       0      0       0        0        0           0          1       0   \n",
      "49         0      0       0        0        1           0          0       0   \n",
      "897        0      0       0        0        0           1          0       0   \n",
      "1899       0      0       0        0        0           0          1       0   \n",
      "1374       0      0       0        0        0           0          1       0   \n",
      "1435       0      0       0        0        0           0          1       0   \n",
      "198        1      0       0        0        0           0          0       0   \n",
      "1550       0      0       0        0        0           0          1       0   \n",
      "1          0      0       0        0        1           0          0       0   \n",
      "2421       0      0       0        0        0           0          0       0   \n",
      "2084       0      0       0        0        0           0          0       1   \n",
      "924        0      0       0        0        0           1          0       0   \n",
      "295        1      0       0        0        0           0          0       0   \n",
      "583        0      0       1        0        0           0          0       0   \n",
      "2407       0      0       0        0        0           0          0       0   \n",
      "977        0      0       0        0        0           1          0       0   \n",
      "250        1      0       0        0        0           0          0       0   \n",
      "290        1      0       0        0        0           0          0       0   \n",
      "2213       0      0       0        0        0           0          0       1   \n",
      "1570       0      0       0        0        0           0          1       0   \n",
      "477        0      0       1        0        0           0          0       0   \n",
      "1019       0      0       0        0        0           1          0       0   \n",
      "2116       0      0       0        0        0           0          0       1   \n",
      "1963       0      0       0        0        0           0          1       0   \n",
      "2124       0      0       0        0        0           0          0       1   \n",
      "819        0      0       0        1        0           0          0       0   \n",
      "1731       0      0       0        0        0           0          1       0   \n",
      "2151       0      0       0        0        0           0          0       1   \n",
      "...      ...    ...     ...      ...      ...         ...        ...     ...   \n",
      "2462       0      0       0        0        0           0          0       0   \n",
      "1609       0      0       0        0        0           0          1       0   \n",
      "1152       0      0       0        0        0           1          0       0   \n",
      "1650       0      0       0        0        0           0          1       0   \n",
      "1984       0      0       0        0        0           0          1       0   \n",
      "1843       0      0       0        0        0           0          1       0   \n",
      "151        1      0       0        0        0           0          0       0   \n",
      "2214       0      0       0        0        0           0          0       1   \n",
      "2399       0      0       0        0        0           0          0       0   \n",
      "541        0      0       1        0        0           0          0       0   \n",
      "1953       0      0       0        0        0           0          1       0   \n",
      "1690       0      0       0        0        0           0          1       0   \n",
      "64         0      0       0        0        1           0          0       0   \n",
      "1638       0      0       0        0        0           0          1       0   \n",
      "1421       0      0       0        0        0           0          1       0   \n",
      "1208       0      0       0        0        0           1          0       0   \n",
      "273        1      0       0        0        0           0          0       0   \n",
      "2360       0      0       0        0        0           0          0       0   \n",
      "553        0      0       1        0        0           0          0       0   \n",
      "521        0      0       1        0        0           0          0       0   \n",
      "1171       0      0       0        0        0           1          0       0   \n",
      "1239       0      0       0        0        0           1          0       0   \n",
      "140        1      0       0        0        0           0          0       0   \n",
      "2221       0      0       0        0        0           0          0       1   \n",
      "723        0      0       1        0        0           0          0       0   \n",
      "1205       0      0       0        0        0           1          0       0   \n",
      "2168       0      0       0        0        0           0          0       1   \n",
      "15         0      0       0        0        1           0          0       0   \n",
      "632        0      0       1        0        0           0          0       0   \n",
      "1629       0      0       0        0        0           0          1       0   \n",
      "\n",
      "      Shakespeare  \n",
      "2417            1  \n",
      "1791            0  \n",
      "1666            0  \n",
      "49              0  \n",
      "897             0  \n",
      "1899            0  \n",
      "1374            0  \n",
      "1435            0  \n",
      "198             0  \n",
      "1550            0  \n",
      "1               0  \n",
      "2421            1  \n",
      "2084            0  \n",
      "924             0  \n",
      "295             0  \n",
      "583             0  \n",
      "2407            1  \n",
      "977             0  \n",
      "250             0  \n",
      "290             0  \n",
      "2213            0  \n",
      "1570            0  \n",
      "477             0  \n",
      "1019            0  \n",
      "2116            0  \n",
      "1963            0  \n",
      "2124            0  \n",
      "819             0  \n",
      "1731            0  \n",
      "2151            0  \n",
      "...           ...  \n",
      "2462            1  \n",
      "1609            0  \n",
      "1152            0  \n",
      "1650            0  \n",
      "1984            0  \n",
      "1843            0  \n",
      "151             0  \n",
      "2214            0  \n",
      "2399            1  \n",
      "541             0  \n",
      "1953            0  \n",
      "1690            0  \n",
      "64              0  \n",
      "1638            0  \n",
      "1421            0  \n",
      "1208            0  \n",
      "273             0  \n",
      "2360            1  \n",
      "553             0  \n",
      "521             0  \n",
      "1171            0  \n",
      "1239            0  \n",
      "140             0  \n",
      "2221            0  \n",
      "723             0  \n",
      "1205            0  \n",
      "2168            0  \n",
      "15              0  \n",
      "632             0  \n",
      "1629            0  \n",
      "\n",
      "[1404 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 10) (1404, 9)\n",
      "(469, 10) (469, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_count.shape, y_train.shape)\n",
    "print(x_test_count.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1404 samples, validate on 469 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.3209 - acc: 0.8883 - val_loss: 0.3184 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.3184 - acc: 0.8889 - val_loss: 0.3181 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.3180 - acc: 0.8889 - val_loss: 0.3180 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.3171 - acc: 0.8889 - val_loss: 0.3196 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.3185 - acc: 0.8889 - val_loss: 0.3193 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.3180 - acc: 0.8889 - val_loss: 0.3173 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.3174 - acc: 0.8889 - val_loss: 0.3205 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3175 - acc: 0.8889 - val_loss: 0.3174 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3174 - acc: 0.8889 - val_loss: 0.3169 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3170 - acc: 0.8889 - val_loss: 0.3175 - val_acc: 0.8889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_count, y_train, epochs=10, batch_size=32, validation_data=(x_test_count, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469,)\n",
      "(469, 9)\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict_classes(x_test_count)\n",
    "y_predict_train = model.predict_classes(X_train_count)\n",
    "print(y_predict.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "[6 6 6 ... 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)\n",
    "print(y_predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-d9f94cca9173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation()\n",
    "x_lda = lda.fit_transform(X_train_tfidf)\n",
    "x_test_tfidf = lda.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = pad_sequences(x_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2018, 10) (2018, 10)\n",
      "(673, 10) (673, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape, y_train.shape)\n",
    "print(x_test_tfidf.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2018 samples, validate on 673 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.2877 - acc: 0.9000 - val_loss: 0.2876 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.2878 - acc: 0.9000 - val_loss: 0.2867 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.2879 - acc: 0.9000 - val_loss: 0.2867 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      " - 12s - loss: 0.2878 - acc: 0.9000 - val_loss: 0.2869 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      " - 10s - loss: 0.2878 - acc: 0.9000 - val_loss: 0.2869 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.2877 - acc: 0.9000 - val_loss: 0.2876 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.2878 - acc: 0.9000 - val_loss: 0.2868 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.2877 - acc: 0.9000 - val_loss: 0.2866 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      " - 8s - loss: 0.2878 - acc: 0.9000 - val_loss: 0.2866 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      " - 8s - loss: 0.2877 - acc: 0.9000 - val_loss: 0.2871 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_tfidf, y_train, epochs=10, batch_size=5, validation_data=(x_test_tfidf, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfidf = cluster_vectorizer.transform(X_test).toarray()\n",
    "x_test = lda.transform(x_tfidf)\n",
    "y_test = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48947500847901887\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgess</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chesterton</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edgeworth</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>201</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milton</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakespeare</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0  1    2   3  4   5  6  7  8  9\n",
       "1                                            \n",
       "Austen       2  1   65   0  0   1  0  1  0  1\n",
       "Blake        0  0    4   0  0   0  0  0  0  2\n",
       "Bryant       2  2   58   4  1   0  3  7  2  3\n",
       "Burgess      0  4   19   0  2   0  0  1  0  0\n",
       "Carroll      0  0   28   0  0   2  0  0  0  0\n",
       "Chesterton   2  3   86   4  1   0  0  1  2  0\n",
       "Edgeworth    1  0  211   2  1   0  1  3  2  0\n",
       "Melville     1  7  201  17  6  10  5  6  3  5\n",
       "Milton       0  0   54   1  1   0  0  0  0  2\n",
       "Shakespeare  2  7   19   2  6   3  2  1  0  1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = kmeans_lda.predict(x_test)\n",
    "print(silhouette_score(x_test, y_predict))\n",
    "pd.crosstab(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette score looks good for test data also for clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tfidf Test score: \", rfc_tfidf.score(X_test_tfidf, Y_test))\n",
    "print(\"Count Test score: \", rfc_count.score(X_test_count, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tfidf Test score: \", gbc_tfidf.score(X_test_tfidf, Y_test))\n",
    "print(\"Count Test score: \", gbc_count.score(X_test_count, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tfidf Test score: \", lr_tfidf.score(X_test_tfidf, Y_test))\n",
    "print(\"Count Test score: \", lr_count.score(X_test_count, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
